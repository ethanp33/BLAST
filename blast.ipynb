{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blast Application - By Ethan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from lxml import etree as et\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previously made command line script, we can write a function that inputs a file name (including the file extension) and run a blast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blast(file_name: str, blast_type: str, max_hits: int = None, megablast: bool = False, e_value_threshold: float = None):\n",
    "    \"\"\"\n",
    "    A function that runs a BLAST of desired type and saves the results as an xml file. \n",
    "    :inputs: file_name (including file extension), blast_type (one of blastn, blastp, tblastn or tblastx)\n",
    "    :returns: None\n",
    "    \"\"\" \n",
    "\n",
    "    # Error check\n",
    "    if blast_type.lower() in [\"blastn\", \"blastp\", \"blastx\", \"tblastn\", \"tblastx\"]:\n",
    "        \n",
    "        # Open sequence file\n",
    "        seq_file = next(SeqIO.parse(open(file_name), \"fasta\"))\n",
    "\n",
    "        # Megablast\n",
    "        if blast_type == \"blastn\":\n",
    "            if megablast == True:\n",
    "                query = NCBIWWW.qblast(blast_type, \"nt\", seq_file.seq, megablast=True)\n",
    "\n",
    "        # Start query\n",
    "        print(\"Starting BLAST query on NCBI database...\")\n",
    "        print(\"Please hold. This process can take up to 10 minutes to complete...\")\n",
    "        query = NCBIWWW.qblast(blast_type, \"nt\", seq_file.seq)\n",
    "        print(query)\n",
    "\n",
    "        # Store results as XML\n",
    "        print(\"Storing results as an XML file...\")\n",
    "        with open(str(file_name).split(\".\")[0] + \"_results.xml\", \"w\") as save_file:\n",
    "            blast_results = query.read()\n",
    "            save_file.write(blast_results)\n",
    "\n",
    "        print(\"Success! \" + str(file_name).split(\".\")[0] + \"_results.xml has been saved!\")\n",
    "        \n",
    "        # Make raw dataframe\n",
    "        print(\"Parsing XML file as dataframe...\")\n",
    "        df = pd.read_xml(str(file_name).split(\".\")[0] + \"_results.xml\", xpath=\".//Hsp\")\n",
    "        \n",
    "        # Edit raw dataframe\n",
    "        # Rename and drop columns\n",
    "        df = df.drop([\"Hsp_num\", \"Hsp_qseq\", \"Hsp_query-frame\", \"Hsp_hit-frame\"], axis=1)\n",
    "        df = df.rename(columns={\"Hsp_bit-score\" : \"bit_score\", \"Hsp_score\" : \"score\", \"Hsp_evalue\" : \"evalue\", \"Hsp_query-from\" : \"query_from\", \"Hsp_query-to\" : \"query_to\",\n",
    "        \"Hsp_hit-from\" : \"hit_from\", \"Hsp_hit-to\" : \"hit_to\", \"Hsp_identity\" : \"identity\", \"Hsp_positive\" : \"positive\", \"Hsp_gaps\" : \"gaps\", \"Hsp_align-len\" : \"align_len\",\n",
    "        \"Hsp_hseq\" : \"hit_seq\", \"Hsp_midline\" : \"midline\"})\n",
    "\n",
    "        # Add new columns based on Hit XML alltributes\n",
    "        tree = et.parse(open(str(file_name).split(\".\")[0] + \"_results.xml\"))\n",
    "        hit_id = tree.xpath(\".//Hit/Hit_id/text()\")\n",
    "        hit_def = tree.xpath(\".//Hit/Hit_def/text()\")\n",
    "        hit_accession = tree.xpath(\".//Hit/Hit_accession/text()\")\n",
    "        hit_length = tree.xpath(\".//Hit/Hit_len/text()\")\n",
    "        df[\"id\"] = hit_id\n",
    "        df[\"description\"] = hit_def\n",
    "        df[\"accession\"] = hit_accession\n",
    "        df[\"acc_len\"] = hit_length\n",
    "\n",
    "        # Calculating percent identity\n",
    "        df[\"per_ident\"] = np.round((df[\"identity\"] / df[\"align_len\"])*100, decimals=2)\n",
    "\n",
    "        # Calculating query coverage\n",
    "        df[\"query_cover\"] = np.round((df[\"query_to\"] - df[\"query_from\"] + 1)/len(seq_file.seq)*100, decimals=2)\n",
    "\n",
    "        # Change order of columns\n",
    "        df = df[[\"id\", \"description\", \"bit_score\", \"score\", \"query_cover\", \"per_ident\", \"evalue\", \"query_from\", \"query_to\", \n",
    "        \"hit_from\", \"hit_to\", \"identity\", \"positive\", \"gaps\", \"align_len\", \"acc_len\", \"hit_seq\", \"midline\", \"accession\"]]\n",
    "\n",
    "        # Remove rows if e-value is over threshold\n",
    "        if e_value_threshold is not None:\n",
    "            df = df[df.evalue < e_value_threshold]\n",
    "        \n",
    "        # Cap rows/hits if there is a maximum\n",
    "        if max_hits is not None:\n",
    "            df = df.sort_values(by=\"evalue\", ascending=False)\n",
    "            df = df.head(max_hits)\n",
    "\n",
    "        # Save editted dataframe\n",
    "        print(\"Saving dataframe as csv file...\")\n",
    "        df.to_csv(str(file_name).split(\".\")[0] + \"_dataframe.csv\")\n",
    "\n",
    "        # End\n",
    "        print(\"Success! Dataframe has successfully been saved as \" + str(file_name).split(\".\")[0] + \"_dataframe.csv\" + \". Press any key to exit function.\")\n",
    "    else:\n",
    "        print(\"blast_type not one of blastn, blastp, blastx, tblastn or tblastx\")\n",
    "        blast(file_name=file_name, blast_type=blast_type, max_hits=max_hits, megablast=megablast, e_value_threshold=e_value_threshold)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a test of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BLAST query on NCBI database...\n",
      "Please hold. This process can take up to 10 minutes to complete...\n",
      "<_io.StringIO object at 0x000002198DD46790>\n",
      "Storing results as an XML file...\n",
      "Success! aporrectodea_rosea_results.xml has been saved!\n",
      "Parsing XML file as dataframe...\n",
      "Saving dataframe as csv file...\n",
      "Success! Dataframe has successfully been saved as aporrectodea_rosea_dataframe.csv. Press any key to exit function.\n"
     ]
    }
   ],
   "source": [
    "blast(file_name=\"aporrectodea_rosea.fna\", blast_type=\"blastn\", max_hits=5, megablast=False, e_value_threshold=1e-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the dataframe. Here is the csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>bit_score</th>\n",
       "      <th>score</th>\n",
       "      <th>query_cover</th>\n",
       "      <th>per_ident</th>\n",
       "      <th>evalue</th>\n",
       "      <th>query_from</th>\n",
       "      <th>query_to</th>\n",
       "      <th>hit_from</th>\n",
       "      <th>hit_to</th>\n",
       "      <th>identity</th>\n",
       "      <th>positive</th>\n",
       "      <th>gaps</th>\n",
       "      <th>align_len</th>\n",
       "      <th>acc_len</th>\n",
       "      <th>hit_seq</th>\n",
       "      <th>midline</th>\n",
       "      <th>accession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gi|1829765830|ref|NC_046733.1|</td>\n",
       "      <td>Aporrectodea rosea haplogroup L4 mitochondrion...</td>\n",
       "      <td>2778.47</td>\n",
       "      <td>3080</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1540</td>\n",
       "      <td>1</td>\n",
       "      <td>1540</td>\n",
       "      <td>1540</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>1540</td>\n",
       "      <td>15086</td>\n",
       "      <td>ATGCGATGATTTTACTCAACCAATCACAAAGATATTGGAACTTTAT...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>NC_046733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>gi|1068288817|gb|KU728851.1|</td>\n",
       "      <td>Enchytraeus cf. crypticus SL-2017 cytochrome c...</td>\n",
       "      <td>1349.30</td>\n",
       "      <td>1495</td>\n",
       "      <td>99.09</td>\n",
       "      <td>79.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1526</td>\n",
       "      <td>1</td>\n",
       "      <td>1523</td>\n",
       "      <td>1215</td>\n",
       "      <td>1215</td>\n",
       "      <td>3</td>\n",
       "      <td>1526</td>\n",
       "      <td>1539</td>\n",
       "      <td>ATGCGCTGACTATATTCTACAAACCACAAAGACATTGGTACACTAT...</td>\n",
       "      <td>||||| ||| | || || || || |||||||| ||||| ||  |||...</td>\n",
       "      <td>KU728851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>gi|1003312217|gb|KT429019.1|</td>\n",
       "      <td>Amynthas robustus mitochondrion, complete genome</td>\n",
       "      <td>1387.18</td>\n",
       "      <td>1537</td>\n",
       "      <td>99.74</td>\n",
       "      <td>80.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1536</td>\n",
       "      <td>1</td>\n",
       "      <td>1536</td>\n",
       "      <td>1229</td>\n",
       "      <td>1229</td>\n",
       "      <td>0</td>\n",
       "      <td>1536</td>\n",
       "      <td>15013</td>\n",
       "      <td>ATGCGATGATTATATTCTACAAACCACAAAGACATTGGAACCCTAT...</td>\n",
       "      <td>||||||||||| || || || || |||||||| ||||||||  |||...</td>\n",
       "      <td>KT429019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>gi|827022294|gb|KP688582.1|</td>\n",
       "      <td>Amynthas gracilis mitochondrion, complete genome</td>\n",
       "      <td>1381.77</td>\n",
       "      <td>1531</td>\n",
       "      <td>99.22</td>\n",
       "      <td>80.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1528</td>\n",
       "      <td>1</td>\n",
       "      <td>1528</td>\n",
       "      <td>1223</td>\n",
       "      <td>1223</td>\n",
       "      <td>0</td>\n",
       "      <td>1528</td>\n",
       "      <td>15161</td>\n",
       "      <td>ATGCGATGATTGTATTCTACAAACCACAAAGACATTGGAACCCTAT...</td>\n",
       "      <td>||||||||||| || || || || |||||||| ||||||||  |||...</td>\n",
       "      <td>KP688582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>gi|1003312161|gb|KT429015.1|</td>\n",
       "      <td>Duplodicodrilus schmardae mitochondrion, compl...</td>\n",
       "      <td>1379.96</td>\n",
       "      <td>1529</td>\n",
       "      <td>99.81</td>\n",
       "      <td>79.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1537</td>\n",
       "      <td>1</td>\n",
       "      <td>1537</td>\n",
       "      <td>1228</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>1537</td>\n",
       "      <td>15156</td>\n",
       "      <td>ATGCGATGATTATATTCTACAAATCACAAAGACATTGGAACTTTAT...</td>\n",
       "      <td>||||||||||| || || || ||||||||||| |||||||||||||...</td>\n",
       "      <td>KT429015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              id  \\\n",
       "0           0  gi|1829765830|ref|NC_046733.1|   \n",
       "1          37    gi|1068288817|gb|KU728851.1|   \n",
       "2          27    gi|1003312217|gb|KT429019.1|   \n",
       "3          28     gi|827022294|gb|KP688582.1|   \n",
       "4          29    gi|1003312161|gb|KT429015.1|   \n",
       "\n",
       "                                         description  bit_score  score  \\\n",
       "0  Aporrectodea rosea haplogroup L4 mitochondrion...    2778.47   3080   \n",
       "1  Enchytraeus cf. crypticus SL-2017 cytochrome c...    1349.30   1495   \n",
       "2   Amynthas robustus mitochondrion, complete genome    1387.18   1537   \n",
       "3   Amynthas gracilis mitochondrion, complete genome    1381.77   1531   \n",
       "4  Duplodicodrilus schmardae mitochondrion, compl...    1379.96   1529   \n",
       "\n",
       "   query_cover  per_ident  evalue  query_from  query_to  hit_from  hit_to  \\\n",
       "0       100.00     100.00       0           1      1540         1    1540   \n",
       "1        99.09      79.62       0           1      1526         1    1523   \n",
       "2        99.74      80.01       0           1      1536         1    1536   \n",
       "3        99.22      80.04       0           1      1528         1    1528   \n",
       "4        99.81      79.90       0           1      1537         1    1537   \n",
       "\n",
       "   identity  positive  gaps  align_len  acc_len  \\\n",
       "0      1540      1540     0       1540    15086   \n",
       "1      1215      1215     3       1526     1539   \n",
       "2      1229      1229     0       1536    15013   \n",
       "3      1223      1223     0       1528    15161   \n",
       "4      1228      1228     0       1537    15156   \n",
       "\n",
       "                                             hit_seq  \\\n",
       "0  ATGCGATGATTTTACTCAACCAATCACAAAGATATTGGAACTTTAT...   \n",
       "1  ATGCGCTGACTATATTCTACAAACCACAAAGACATTGGTACACTAT...   \n",
       "2  ATGCGATGATTATATTCTACAAACCACAAAGACATTGGAACCCTAT...   \n",
       "3  ATGCGATGATTGTATTCTACAAACCACAAAGACATTGGAACCCTAT...   \n",
       "4  ATGCGATGATTATATTCTACAAATCACAAAGACATTGGAACTTTAT...   \n",
       "\n",
       "                                             midline  accession  \n",
       "0  ||||||||||||||||||||||||||||||||||||||||||||||...  NC_046733  \n",
       "1  ||||| ||| | || || || || |||||||| ||||| ||  |||...   KU728851  \n",
       "2  ||||||||||| || || || || |||||||| ||||||||  |||...   KT429019  \n",
       "3  ||||||||||| || || || || |||||||| ||||||||  |||...   KP688582  \n",
       "4  ||||||||||| || || || ||||||||||| |||||||||||||...   KT429015  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"aporrectodea_rosea_dataframe.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing BLAST multiple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blast_multiple(folder_directory: str, blast_type: str, max_hits: int = None, megablast: bool = False, e_value_threshold: float = None):\n",
    "    \"\"\"\n",
    "    A function that runs multiple BLASTs of a desired type and saves the results as a csv file.\n",
    "    :inputs: folder_directory, blast_type (one of blastn, blastp, tblastn or tblastx), \n",
    "            max_hits, megablast, e_value_threshold\n",
    "    :returns: None\n",
    "    \"\"\" \n",
    "\n",
    "    # Imports\n",
    "    from Bio.Blast import NCBIWWW, NCBIXML\n",
    "    from Bio import SeqIO\n",
    "    import pandas as pd\n",
    "    from lxml import etree as et\n",
    "    import numpy as np\n",
    "    from blast import blast\n",
    "\n",
    "    # Get each file\n",
    "    file_names = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(folder_directory):\n",
    "        f = os.path.join(folder_directory, filename)\n",
    "        # Check if the file exists\n",
    "        if os.path.isfile(f) and filename.split(\".\")[-1] == \"fna\":\n",
    "            count += 1\n",
    "            print(\"Searching \" + folder_directory + \". Found \" + str(count) + \" sequences to BLAST so far.\", end=\"\\r\")\n",
    "            file_names.append(str(f))\n",
    "\n",
    "    for file_name in file_names:\n",
    "        count = 0\n",
    "        print(\"Currenting BLASTing \" + str(file_name) + \". Have BLASTed \" + str(count) + \" sequences so far.\", end=\"\\r\")\n",
    "        blast(file_name=file_name, blast_type=blast_type, max_hits=max_hits, megablast=megablast, e_value_threshold=e_value_threshold)\n",
    "    print(\"Success! BlASTed a total of \" + str(count) + \" sequences.\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BLAST query on NCBI database...riensis.fna. Have BLASTed 0 sequences so far.\n",
      "Please hold. This process can take up to 10 minutes to complete...\n",
      "<_io.StringIO object at 0x00000174906950D0>\n",
      "Storing results as an XML file...\n",
      "Success! to_blast\\amynthas_jiriensis_results.xml has been saved!\n",
      "Parsing XML file as dataframe...\n",
      "Saving dataframe as csv file...\n",
      "Success! Dataframe has successfully been saved as to_blast\\amynthas_jiriensis_dataframe.csv. Press any key to exit function.\n",
      "Starting BLAST query on NCBI database...ungpanensis.fna. Have BLASTed 0 sequences so far.\n",
      "Please hold. This process can take up to 10 minutes to complete...\n",
      "<_io.StringIO object at 0x00000174AA12F550>\n",
      "Storing results as an XML file...\n",
      "Success! to_blast\\amynthas_seungpanensis_results.xml has been saved!\n",
      "Parsing XML file as dataframe...\n",
      "Saving dataframe as csv file...\n",
      "Success! Dataframe has successfully been saved as to_blast\\amynthas_seungpanensis_dataframe.csv. Press any key to exit function.\n",
      "Starting BLAST query on NCBI database...a_rosea.fna. Have BLASTed 0 sequences so far.\n",
      "Please hold. This process can take up to 10 minutes to complete...\n",
      "<_io.StringIO object at 0x00000174906950D0>\n",
      "Storing results as an XML file...\n",
      "Success! to_blast\\aporrectodea_rosea_results.xml has been saved!\n",
      "Parsing XML file as dataframe...\n",
      "Saving dataframe as csv file...\n",
      "Success! Dataframe has successfully been saved as to_blast\\aporrectodea_rosea_dataframe.csv. Press any key to exit function.\n",
      "Starting BLAST query on NCBI database...errestris.fna. Have BLASTed 0 sequences so far.\n",
      "Please hold. This process can take up to 10 minutes to complete...\n",
      "<_io.StringIO object at 0x00000174AA12F550>\n",
      "Storing results as an XML file...\n",
      "Success! to_blast\\lumbricus_terrestris_results.xml has been saved!\n",
      "Parsing XML file as dataframe...\n",
      "Saving dataframe as csv file...\n",
      "Success! Dataframe has successfully been saved as to_blast\\lumbricus_terrestris_dataframe.csv. Press any key to exit function.\n",
      "Starting BLAST query on NCBI database...birmanicus.fna. Have BLASTed 0 sequences so far.\n",
      "Please hold. This process can take up to 10 minutes to complete...\n",
      "<_io.StringIO object at 0x00000174AA12F550>\n",
      "Storing results as an XML file...\n",
      "Success! to_blast\\tonoscolex_birmanicus_results.xml has been saved!\n",
      "Parsing XML file as dataframe...\n",
      "Saving dataframe as csv file...\n",
      "Success! Dataframe has successfully been saved as to_blast\\tonoscolex_birmanicus_dataframe.csv. Press any key to exit function.\n",
      "Success! BlASTed a total of 0 sequences.\n"
     ]
    }
   ],
   "source": [
    "blast_multiple(folder_directory = \"to_blast\", blast_type=\"blastn\", max_hits= 5, megablast=False, e_value_threshold=1e-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to work on a sequence downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Bio import Entrez, SeqIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(file_name: str, email_address: str, gene_name: str):\n",
    "    \"\"\"\"\n",
    "    A function that searches the genbank gene database and downloads multiple fasta sequence files\n",
    "    :inputs: file_name (including file extension) of a text file containing line separated species names to download sequences for,\n",
    "            email_address so NCBI knows who is requesting files data if anything goes awry,\n",
    "            gene_name containing the gene of interest to search for\n",
    "    :returns: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Imports\n",
    "    from Bio import Entrez, SeqIO\n",
    "    import time\n",
    "\n",
    "    # Parameters\n",
    "    Entrez.api_key = \"0479a2cd7f6d9e97e14c35e4d49eba018509\"\n",
    "    Entrez.email = email_address\n",
    "\n",
    "    # Read text file\n",
    "    with open(file_name) as f:\n",
    "        species_names = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    # Start search\n",
    "    print(\"Starting search. Please hold as only 10 API requests can be made per second...\")\n",
    "    record_ids = []\n",
    "    record_counts = 0\n",
    "    for species_name in species_names:\n",
    "        handle = Entrez.esearch(db=\"nucleotide\", term=species_name + \"[Orgn] AND COI[Gene]\", idtype=\"acc\", retmax=5000)\n",
    "        record = Entrez.read(handle)\n",
    "        record_counts += int(record[\"Count\"])\n",
    "        record_ids += record[\"IdList\"]\n",
    "        print(\"Found \" + str(record_counts) + \" records so far...\", end=\"\\r\")\n",
    "        handle.close()\n",
    "\n",
    "        # Wait\n",
    "        time.sleep(1)\n",
    "    print(\"Search success! For a search of \" + str(len(species_names)) + \" species, a total of \" + str(record_counts) + \" genbank records containing COI genes were found!\")\n",
    "\n",
    "    # Start download\n",
    "    print(\"Starting sequence download process. Please hold as only 10 API requests can be made per second...\")\n",
    "    count = 0\n",
    "    for record_id in record_ids:\n",
    "        if not os.path.isfile(\"downloads//\" + gene_name + \"//\" + str(record_id) + \".fna\"):\n",
    "            net_handle = Entrez.efetch(db=\"nucleotide\", id=record_id, rettype=\"fasta\", retmode=\"text\", retmax=5000)\n",
    "            out_handle = open(\"downloads//\" + gene_name + \"//\" + str(record_id) + \".fna\", \"w\")\n",
    "            out_handle.write(net_handle.read())\n",
    "            out_handle.close()\n",
    "            net_handle.close()\n",
    "            count += 1\n",
    "            print(\"Downloading record \" + str(record_id) + \" Downloaded \" + str(count) + \" sequences so far...\", end=\"\\r\")\n",
    "\n",
    "            # Wait\n",
    "            time.sleep(1)\n",
    "\n",
    "    # End\n",
    "    print(\"Success! You can find your downloaded sequences in the downloads folder where this script is located!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the download function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search. Please hold as only 10 API requests can be made per second...\n",
      "Search success! For a search of 82 species, a total of 2115 genbank records containing COI genes were found!\n",
      "Starting sequence download process. Please hold as only 10 API requests can be made per second...\n",
      "Success! You can find your downloaded sequences in the downloads folder where this script is located!\n"
     ]
    }
   ],
   "source": [
    "download(file_name=\"nematode_names.txt\", email_address=\"epay0001@student.monash.edu\", gene_name=\"COI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to write a function that checks for any duplicate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(folder_directory: str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Imports\n",
    "    from Bio import SeqIO\n",
    "    import time\n",
    "\n",
    "    # Loop through each file\n",
    "    file_paths_to_remove = set()\n",
    "\n",
    "    for filename_one in os.listdir(folder_directory):\n",
    "        f_one = os.path.join(folder_directory, filename_one)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.isfile(f_one) and filename_one.split(\".\")[-1] == \"fna\":\n",
    "            \n",
    "            with open(f_one) as handle_one:\n",
    "                current_seq = next(SeqIO.parse(handle_one, \"fasta\"))\n",
    "                # Check current_seq against every other file\n",
    "                for filename_two in os.listdir(folder_directory):\n",
    "                    f_two = os.path.join(folder_directory, filename_two)\n",
    "                    \n",
    "                    # Check if the file exists\n",
    "                    if os.path.isfile(f_two) and filename_two.split(\".\")[-1] == \"fna\":\n",
    "                        \n",
    "                        # Check if the file isn't the same as the one we are checking\n",
    "                        if filename_one != filename_two:\n",
    "                            \n",
    "                            with open(f_two) as handle_two:\n",
    "                                check_seq = next(SeqIO.parse(handle_two, \"fasta\"))\n",
    "                                \n",
    "                                print(\"Comparing \" + filename_one + \" to \" + filename_two, end=\"\\r\")\n",
    "                                # Check if the sequences of the fasta files are the same:                     \n",
    "                                if current_seq.seq == check_seq.seq:\n",
    "                                    file_paths_to_remove.add(f_two)\n",
    "            \n",
    "            \n",
    "\n",
    "    print(\"Found: \" + str(len(file_paths_to_remove)) + \" duplicate files to remove. Removing...\")  \n",
    "    \n",
    "    for file_name in file_paths_to_remove:\n",
    "        os.remove(file_name)\n",
    "        # Wait\n",
    "        time.sleep(1)\n",
    "    print(\"Success!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the check_duplicates function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 1112 duplicate files to remove. Removing...\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(folder_directory = \"downloads\\COI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
